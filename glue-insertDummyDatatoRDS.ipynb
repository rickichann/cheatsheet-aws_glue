{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 1.0.5 \n",
						"Current idle_timeout is None minutes.\n",
						"idle_timeout has been set to 15 minutes.\n",
						"Setting Glue version to: 4.0\n",
						"Previous worker type: None\n",
						"Setting new worker type to: G.1X\n",
						"Previous number of workers: None\n",
						"Setting new number of workers to: 2\n",
						"Connections to be included:\n",
						"xledmpoc\n",
						"Trying to create a Glue session for the kernel.\n",
						"Session Type: glueetl\n",
						"Worker Type: G.1X\n",
						"Number of Workers: 2\n",
						"Idle Timeout: 15\n",
						"Session ID: ad263024-fdde-4dda-9207-19c37ab774e2\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 1.0.5\n",
						"--enable-glue-datacatalog true\n",
						"Waiting for session ad263024-fdde-4dda-9207-19c37ab774e2 to get into ready status...\n",
						"Session ad263024-fdde-4dda-9207-19c37ab774e2 has been created.\n",
						"\n"
					]
				}
			],
			"source": [
				"%idle_timeout 15\n",
				"%glue_version 4.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 2\n",
				"%connections rdspostgresqlpoc\n",
				"\n",
				"\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# additional libraries\n",
				"from pyspark.sql.functions import lit\n",
				"import uuid\n",
				"import random\n",
				"from datetime import datetime, timedelta\n",
				"from awsglue.dynamicframe import DynamicFrame"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"def random_timestamp(start, end):\n",
				"    return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
				"\n",
				"num_rows = 1000000  # fill amount of data want to generate\n",
				"start_date = datetime(2024, 8, 1, 0, 0, 0)\n",
				"end_date = datetime(2024, 8, 21, 23, 59, 59)\n",
				"types = [\"TypeA\", \"TypeB\", \"TypeC\", \"TypeD\", \"TypeE\"]  \n",
				"\n",
				"# i = 0\n",
				"for _ in range(num_rows):\n",
				"    if _%10000==0:\n",
				"        \n",
				"        # Generate data\n",
				"        data = []\n",
				"        for _ in range(10000):\n",
				"            id_value = str(uuid.uuid4())\n",
				"            inserted_at = random_timestamp(start_date, end_date)\n",
				"            pubsub_message_id = f\"MSG{random.randint(100, 999)}\"\n",
				"            amountRange1 = f\"{random.randint(100, 500)}-{random.randint(600, 1000)}\"\n",
				"            amountRange2 = f\"{random.randint(100, 500)}-{random.randint(600, 1000)}\"\n",
				"            type_value = random.choice(types)\n",
				"            schg = f\"{random.randint(50, 150)}-{random.randint(200, 300)}\"\n",
				"            validFrom = random_timestamp(start_date, end_date)\n",
				"\n",
				"            data.append((id_value, inserted_at, pubsub_message_id, amountRange1, amountRange2, type_value, schg, validFrom))\n",
				"\n",
				"        columns = [\"id\", \"inserted_at\", \"pubsub_message_id\", \"amountRange1\", \"amountRange2\", \"type\", \"schg\", \"validFrom\"]\n",
				"        df = spark.createDataFrame(data, schema=columns)\n",
				"        \n",
				"        dy_s_chg = DynamicFrame.fromDF(df, glueContext, \"dy_s_chg\")\n",
				"        glueContext.write_dynamic_frame.from_jdbc_conf(\n",
				"                        frame = dy_s_chg, \n",
				"                        catalog_connection = \"xledmpoc\", \n",
				"                        connection_options = {\n",
				"                            \"dbtable\": \"s_chg\",  # The target table in your RDS PostgreSQL\n",
				"                            \"database\": \"edmpoc\"  # The target database in your RDS PostgreSQL\n",
				"                        },\n",
				"                        transformation_ctx = \"s_chg\"\n",
				"                    )\n",
				"\n",
				"       "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# df = spark.read \\\n",
				"#     .format(\"parquet\") \\\n",
				"#     .load(\"s3://xlaxiata-poc-edm-touchpoint/DummyData/s_chgs_dummy/\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# def random_timestamp(start, end):\n",
				"#     return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
				"\n",
				"# num_rows = 1000000  # fill amount of data want to generate\n",
				"# start_date = datetime(2024, 8, 1, 0, 0, 0)\n",
				"# end_date = datetime(2024, 8, 21, 23, 59, 59)\n",
				"# types = [\"TypeA\", \"TypeB\", \"TypeC\", \"TypeD\", \"TypeE\"]  \n",
				"\n",
				"# i = 0\n",
				"# for _ in range(num_rows):\n",
				"#     if _%10000==0:\n",
				"        \n",
				"#         # Generate data\n",
				"#         data = []\n",
				"#         for _ in range(10000):\n",
				"#             id_value = str(uuid.uuid4())\n",
				"#             inserted_at = random_timestamp(start_date, end_date)\n",
				"#             pubsub_message_id = f\"MSG{random.randint(100, 999)}\"\n",
				"#             amountRange1 = f\"{random.randint(100, 500)}-{random.randint(600, 1000)}\"\n",
				"#             amountRange2 = f\"{random.randint(100, 500)}-{random.randint(600, 1000)}\"\n",
				"#             type_value = random.choice(types)\n",
				"#             schg = f\"{random.randint(50, 150)}-{random.randint(200, 300)}\"\n",
				"#             validFrom = random_timestamp(start_date, end_date)\n",
				"\n",
				"#             data.append((id_value, inserted_at, pubsub_message_id, amountRange1, amountRange2, type_value, schg, validFrom))\n",
				"\n",
				"#         columns = [\"id\", \"inserted_at\", \"pubsub_message_id\", \"amountRange1\", \"amountRange2\", \"type\", \"schg\", \"validFrom\"]\n",
				"#         df = spark.createDataFrame(data, schema=columns)\n",
				"\n",
				"#         nama_file = \"s_chgs_dummy\"\n",
				"#         s3_bucket = f\"s3://xlaxiata-poc-edm-touchpoint/DummyData/{nama_file}\"\n",
				"#         df.coalesce(1).write.parquet(s3_bucket, mode=\"append\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
